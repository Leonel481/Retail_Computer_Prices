{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import json\n",
    "s=HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre el archivo JSON en modo lectura\n",
    "with open('env/Direcciones_url.json', 'r') as archivo_json:\n",
    "    # Carga el contenido del archivo JSON en un diccionario\n",
    "    enlaces = json.load(archivo_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Iterador(f):\n",
    "    \"\"\"Función que permite descargar los datos 15 veces como máximo y los consolida en una tabla total para posteriormente eliminar los duplicados\n",
    "    en función del código de referencia y mantiene los datos más recientes\"\"\"\n",
    "    def Wrapper(*args):\n",
    "        data = pd.DataFrame()\n",
    "        for r in range(0, 15):\n",
    "            dft = f(*args)\n",
    "            if r == 0:\n",
    "                y = len(dft)\n",
    "            data = pd.concat([data, dft])\n",
    "            data = data.drop_duplicates(subset=['codes'], keep='last')\n",
    "            if len(data)>=y:\n",
    "                break\n",
    "            else:\n",
    "                pass\n",
    "        return data\n",
    "    return Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Impacto:\n",
    "    def __init__(self, url_base, category, source):\n",
    "        self.url_base = url_base\n",
    "        self.category = category\n",
    "        self.source = source\n",
    "        self.list_titles = []\n",
    "        self.list_links = []\n",
    "        self.list_codes = []\n",
    "        self.list_stocks = []\n",
    "        self.list_ratings = []\n",
    "        self.list_prices_usd = []\n",
    "        self.list_prices_pen = []\n",
    "        self.list_images = []        \n",
    "    def __str__(self):\n",
    "        return f\"Extrae informacion de la categoria: {self.category} y la almacenada: {self.source}\"\n",
    "    def pagination(self):\n",
    "        r = s.get(self.url_base + self.category)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        pages = soup.find('ul',class_= 'pagination')\n",
    "        number_pag = int(pages.find_all('a', class_= 'page-link')[-2].text)\n",
    "        return number_pag\n",
    "    def scraper(self, n):\n",
    "        for i in range(1, n + 1):\n",
    "            url = self.url_base + self.category + \"&page=\" + str(i)\n",
    "            r = requests.get(url)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            titles = soup.find_all('h4', class_='product-title')\n",
    "            details = soup.find_all('div', class_='detail')\n",
    "            ratings = soup.find_all('ul', class_='product-rating')\n",
    "            prices = soup.find_all('div', class_='product-price')\n",
    "            images = soup.find_all('div', class_='product-image')\n",
    "\n",
    "            for title in titles:\n",
    "                a = title.text.strip()\n",
    "                self.list_titles.append(a)\n",
    "                b = title.find('a')['href']  \n",
    "                self.list_links.append(b)\n",
    "\n",
    "            for detail in details:\n",
    "                a = detail.text.strip()\n",
    "                list_temp = a.split('\\n')\n",
    "                b = re.sub(r'[\\D]+', '', list_temp[0])\n",
    "                c = re.sub(r'[\\D]+', '', list_temp[1])\n",
    "                self.list_codes.append(b)\n",
    "                self.list_stocks.append(c)\n",
    "\n",
    "            for rating in ratings:\n",
    "                list_temp_r = rating.find_all('li', class_='rating-on')\n",
    "                self.list_ratings.append(len(list_temp_r))\n",
    "\n",
    "            for price in prices:\n",
    "                list_temp_pr = price.text.strip().split('\\n')\n",
    "                p_sol = float(re.sub(r'[\\s$\\-,]+','',list_temp_pr[0]))\n",
    "                p_dollar = float(re.sub(r'[\\sS\\-\\/,]+','',list_temp_pr[1]))\n",
    "                self.list_prices_usd.append(p_sol)\n",
    "                self.list_prices_pen.append(p_dollar)\n",
    "\n",
    "            for image in images:\n",
    "                i = image.find('img')['src']\n",
    "                self.list_images.append(i)\n",
    "            data = {'titles':self.list_titles, 'links':self.list_links, 'codes':self.list_codes, 'stocks':self.list_stocks,\n",
    "                    'ratings':self.list_ratings, 'prices_usd':self.list_prices_usd, 'prices_pen':self.list_prices_pen, 'images':self.list_images}\n",
    "        dataDF = pd.DataFrame(data = data)\n",
    "        dataDF['Fecha'] = datetime.now().strftime('%d-%m-%Y %H:%M')\n",
    "        return dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placas Madre Placas%20Madre&c=17 (82, 10)\n",
      "Cooler Refrigeración Cooler%20Refrigeración&c=29 (74, 10)\n",
      "Menoria Ram Memoria%20Ram&c=14 (62, 10)\n",
      "Cases Cases&c=2 (113, 10)\n",
      "Fuentes de Poder Fuentes%20de%20Poder&c=8 (40, 10)\n",
      "Procesador Procesador&c=19 (54, 10)\n",
      "Almacenanmiento Almacenamiento&c=6 (96, 10)\n",
      "Tarjeta de Video Tarjeta%20de%20Video&c=25 (36, 10)\n",
      "Monitores Monitores&c=16 (59, 10)\n"
     ]
    }
   ],
   "source": [
    "data_test1 = pd.DataFrame()\n",
    "for k, v in enlaces['Impacto']['Categorias'].items():\n",
    "    I_componentes = Impacto(enlaces['Impacto']['Principal'], v, 'df')\n",
    "    I_componentes_pag = I_componentes.pagination()\n",
    "    I_componentes_datos = I_componentes.scraper(I_componentes_pag)\n",
    "    I_componentes_datos['Categoria'] = k\n",
    "    data_test1 = pd.concat([data_test1, I_componentes_datos])\n",
    "    print(k, v, I_componentes_datos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test1.to_excel('C:/Users/raini/Downloads/brochure espec web scraping.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_componentes = Impacto(enlaces['Impacto']['Principal'],'731-arma-tu-pc','df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_componentes = Impacto('731-arma-tu-pc','df')\n",
    "I_componentes_pag = I_componentes.pagination()\n",
    "I_componentes_datos = I_componentes.scraper(I_componentes_pag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sercoplus:\n",
    "    headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 Edg/117.0.2045.47'}\n",
    "    def __init__(self, url_base, category, source):\n",
    "        self.url_base = url_base\n",
    "        self.category = category\n",
    "        self.source = source\n",
    "        self.list_titles=[]\n",
    "        self.list_links=[]\n",
    "        self.list_stocks=[]\n",
    "        self.list_codes=[]\n",
    "        self.list_prices_usd=[]\n",
    "        self.list_prices_pen=[]\n",
    "        self.list_images = []\n",
    "    def __str__(self):\n",
    "        return f\"Extrae informacion de la categoria: {self.category} y la almacenada: {self.source}\"\n",
    "    def pagination(self):\n",
    "        \"\"\"Permite obtener el número de páginas totales de la categoria a escrapear\"\"\"\n",
    "        url = self.url_base + self.category\n",
    "        r = requests.get(url, headers=self.headers)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        pages = soup.find('ul', class_='page-list')\n",
    "        pagina_final = pages.find_all('a', class_='js-search-link')[-2].text\n",
    "        pagina_final = int(pagina_final.strip())\n",
    "        return pagina_final\n",
    "    @Iterador\n",
    "    def scraper(self, n):\n",
    "        session = requests.Session()\n",
    "        for i in range(1, n + 1):\n",
    "            if i == 1:\n",
    "                url = self.url_base + self.category\n",
    "            else:\n",
    "                url = self.url_base + self.category + '?page=' + str(i)\n",
    "            r = session.get(url, headers=self.headers)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            blocks = soup.find_all('article', class_ = \"product-miniature js-product-miniature\")\n",
    "            for block in blocks:\n",
    "                first_block = block.find_all('a', class_='product-cover-link')\n",
    "                self.list_links.append(first_block[0]['href'])\n",
    "                self.list_titles.append(first_block[0].find('img', class_=\"img-fluid js-lazy\")['title'])\n",
    "                try:\n",
    "                    img = first_block[0].find('img', class_=\"img-fluid js-lazy\")['data-original']\n",
    "                    self.list_images.append(img)\n",
    "                except KeyError:\n",
    "                    self.list_images.append(None)\n",
    "                third_block = block.find_all('div', class_='product-price-and-shipping d-flex flex-column')\n",
    "                stock = third_block[0].find_all('span', class_ = 'price product-price stock-mini')[1]['data-stock']\n",
    "                code = third_block[0].find_all('span', class_ = 'price product-price stock-mini')[3].text\n",
    "                price_usd = re.sub(r'[^\\d,]', '', third_block[0].find_all('span', class_='price product-price currency2')[0].text).replace(',', '.')\n",
    "                price_pen = re.sub(r'[^\\d,]', '', third_block[0].find_all('span', class_='price product-price currency2')[1].text).replace(',', '.')\n",
    "                self.list_stocks.append(int(stock.strip()))\n",
    "                self.list_codes.append(code.strip())\n",
    "                self.list_prices_usd.append(float(price_usd))\n",
    "                self.list_prices_pen.append(float(price_pen))\n",
    "            data = {'titles':self.list_titles, 'links':self.list_links, 'codes':self.list_codes, 'stocks':self.list_stocks,\n",
    "                    'prices_usd':self.list_prices_usd, 'prices_pen':self.list_prices_pen, 'images':self.list_images}\n",
    "        dataDF = pd.DataFrame(data = data)\n",
    "        dataDF['Fecha'] = datetime.now().strftime('%d-%m-%Y %H:%M')\n",
    "        return dataDF\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_componentes = Sercoplus('731-arma-tu-pc','df')\n",
    "S_componentes_pag = S_componentes.pagination()\n",
    "S_componentes_datos = S_componentes.scraper(S_componentes_pag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cyccomputer:\n",
    "    headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36 Edg/117.0.2045.47'}\n",
    "    def __init__(self, url_base, category, source):\n",
    "        self.url_base = url_base\n",
    "        self.category = category\n",
    "        self.source = source\n",
    "        self.list_titles=[]\n",
    "        self.list_links=[]\n",
    "        self.list_stocks=[]\n",
    "        self.list_codes=[]\n",
    "        self.list_prices_usd=[]\n",
    "        self.list_prices_pen=[]\n",
    "        self.list_images = []\n",
    "    def __str__(self):\n",
    "        return f\"Extrae informacion de la categoria: {self.category} y la almacenada: {self.source}\"\n",
    "    def pagination(self):\n",
    "        \"\"\"Permite obtener el número de páginas totales de la categoria a escrapear\"\"\"\n",
    "        url = self.url_base + self.category\n",
    "        r = requests.get(url, headers=self.headers)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        pages = soup.find('ul', class_='page-list clearfix text-sm-center')\n",
    "        pagina_final = pages.find_all('a', class_='js-search-link')[-2].text\n",
    "        pagina_final = int(pagina_final.strip())\n",
    "        return pagina_final\n",
    "    @Iterador\n",
    "    def scraper(self, n):\n",
    "        session = requests.Session()\n",
    "        for i in range(1, n + 1):\n",
    "            if i == 1:\n",
    "                url = self.url_base + self.category\n",
    "            else:\n",
    "                url = self.url_base + self.category + '?page=' + str(i)\n",
    "            r = session.get(url, headers=self.headers)\n",
    "            soup = BeautifulSoup(r.text, 'html.parser')\n",
    "            soup_product = soup.find('div', class_ = \"laberProductGrid laberProducts\")\n",
    "            total_blocks = soup_product.find_all('article', class_ = \"product-miniature js-product-miniature\")\n",
    "            for total_block in total_blocks:\n",
    "                code = total_block[\"data-id-product\"]\n",
    "                block = total_block.find('div', class_ = \"laberProduct-container\")\n",
    "                link = block.find('a', class_ = \"thumbnail product-thumbnail\").get('href')\n",
    "                image = block.find('a', class_ = \"thumbnail product-thumbnail\").find('span', class_ = \"cover_image\").find('img').get('src')\n",
    "                titule = block.find('h2', class_ = \"productName\").text\n",
    "                stock = re.sub(r'[^\\d]', '', block.find('div', class_ = \"product-quantities manufacturer_name\").text)\n",
    "                price_usd = re.sub(r'[^\\d,]', '', block.find_all('span', class_ = \"price pr\")[0].text).replace(',','.')\n",
    "                price_pen = re.sub(r'[^\\d,]', '', block.find_all('span', class_ = \"price pr\")[1].text).replace(',','.')\n",
    "                self.list_codes.append(code.strip())\n",
    "                self.list_links.append(link)\n",
    "                self.list_images.append(image)\n",
    "                self.list_titles.append(titule.strip())\n",
    "                self.list_stocks.append(int(stock.strip()))\n",
    "                self.list_prices_usd.append(float(price_usd))\n",
    "                self.list_prices_pen.append(float(price_pen))\n",
    "            data = {'titles':self.list_titles, 'links':self.list_links, 'codes':self.list_codes, 'stocks':self.list_stocks,\n",
    "                    'prices_usd':self.list_prices_usd, 'prices_pen':self.list_prices_pen, 'images':self.list_images}\n",
    "        dataDF = pd.DataFrame(data = data)\n",
    "        dataDF['Fecha'] = datetime.now().strftime('%d-%m-%Y %H:%M')\n",
    "        return dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_componentes = Cyccomputer('250-pc-componente','df')\n",
    "C_componentes_pag = C_componentes.pagination()\n",
    "C_componentes_pag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>links</th>\n",
       "      <th>codes</th>\n",
       "      <th>stocks</th>\n",
       "      <th>prices_usd</th>\n",
       "      <th>prices_pen</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>PROCESADOR INTEL CORE I7-10700 2.90 GHZ/16MB L...</td>\n",
       "      <td>https://cyccomputer.pe/10th-generacion-lga-120...</td>\n",
       "      <td>15343</td>\n",
       "      <td>2</td>\n",
       "      <td>268.0</td>\n",
       "      <td>1045.2</td>\n",
       "      <td>https://cyccomputer.pe/30163-home_default/proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>PLACA MSI PRO B550M-P GEN3 AMD RYZEN DDR4 AM4 ...</td>\n",
       "      <td>https://cyccomputer.pe/socket-am4-ryzen/26386-...</td>\n",
       "      <td>26386</td>\n",
       "      <td>10</td>\n",
       "      <td>92.0</td>\n",
       "      <td>358.8</td>\n",
       "      <td>https://cyccomputer.pe/50446-home_default/plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>MONITOR LED 24\" SAMSUNG LS24F354FHLXPE 1920x10...</td>\n",
       "      <td>https://cyccomputer.pe/monitores-multitarea/14...</td>\n",
       "      <td>14756</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>https://cyccomputer.pe/48439-home_default/moni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>SSD 4TB KINGSTON FURY RENEGADE M.2 2280 NVMe P...</td>\n",
       "      <td>https://cyccomputer.pe/ssd-m2-2280-pcie/26431-...</td>\n",
       "      <td>26431</td>\n",
       "      <td>0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>1677.0</td>\n",
       "      <td>https://cyccomputer.pe/50500-home_default/ssd-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>PLACA MSI PRO X670-P WIFI AMD RYZEN DDR5 AM5 (...</td>\n",
       "      <td>https://cyccomputer.pe/-socket-am5-ryzen-/2208...</td>\n",
       "      <td>22089</td>\n",
       "      <td>1</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1431.3</td>\n",
       "      <td>https://cyccomputer.pe/45074-home_default/plac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 titles  \\\n",
       "550   PROCESADOR INTEL CORE I7-10700 2.90 GHZ/16MB L...   \n",
       "1150  PLACA MSI PRO B550M-P GEN3 AMD RYZEN DDR4 AM4 ...   \n",
       "1642  MONITOR LED 24\" SAMSUNG LS24F354FHLXPE 1920x10...   \n",
       "1777  SSD 4TB KINGSTON FURY RENEGADE M.2 2280 NVMe P...   \n",
       "1784  PLACA MSI PRO X670-P WIFI AMD RYZEN DDR5 AM5 (...   \n",
       "\n",
       "                                                  links  codes  stocks  \\\n",
       "550   https://cyccomputer.pe/10th-generacion-lga-120...  15343       2   \n",
       "1150  https://cyccomputer.pe/socket-am4-ryzen/26386-...  26386      10   \n",
       "1642  https://cyccomputer.pe/monitores-multitarea/14...  14756       1   \n",
       "1777  https://cyccomputer.pe/ssd-m2-2280-pcie/26431-...  26431       0   \n",
       "1784  https://cyccomputer.pe/-socket-am5-ryzen-/2208...  22089       1   \n",
       "\n",
       "      prices_usd  prices_pen  \\\n",
       "550        268.0      1045.2   \n",
       "1150        92.0       358.8   \n",
       "1642       130.0       507.0   \n",
       "1777       430.0      1677.0   \n",
       "1784       367.0      1431.3   \n",
       "\n",
       "                                                 images  \n",
       "550   https://cyccomputer.pe/30163-home_default/proc...  \n",
       "1150  https://cyccomputer.pe/50446-home_default/plac...  \n",
       "1642  https://cyccomputer.pe/48439-home_default/moni...  \n",
       "1777  https://cyccomputer.pe/50500-home_default/ssd-...  \n",
       "1784  https://cyccomputer.pe/45074-home_default/plac...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_componentes_datos = C_componentes.scraper(C_componentes_pag)\n",
    "C_componentes_datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
